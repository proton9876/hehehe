{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Training Set:\n",
      "TP: 41 TN: 40 FP: 0 FN: 0\n",
      "Sensitivity (Training): 1.0\n",
      "Specificity (Training): 1.0\n",
      "\n",
      "Confusion Matrix for Testing Set:\n",
      "TP: 9 TN: 10 FP: 0 FN: 0\n",
      "Sensitivity (Testing): 1.0\n",
      "Specificity (Testing): 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets (80:20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features (optional, but can improve convergence)\n",
    "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
    "\n",
    "# Add intercept term\n",
    "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Function to perform logistic regression gradient descent\n",
    "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "    for i in range(iterations):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        theta -= learning_rate * gradient\n",
    "        cost_history.append(compute_cost(X, y, theta))\n",
    "    return theta, cost_history\n",
    "\n",
    "# Function to compute logistic regression cost\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    cost = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    return cost\n",
    "\n",
    "# Initialize theta and hyperparameters\n",
    "theta = np.zeros(X_train.shape[1])\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# Perform gradient descent to train the model\n",
    "theta_trained, cost_history = gradient_descent(X_train, y_train, theta, learning_rate, iterations)\n",
    "\n",
    "# Function to make predictions\n",
    "def predict(X, theta):\n",
    "    probabilities = sigmoid(np.dot(X, theta))\n",
    "    return np.round(probabilities).astype(int)\n",
    "\n",
    "# Make predictions on training and testing sets\n",
    "y_train_pred = predict(X_train, theta_trained)\n",
    "y_test_pred = predict(X_test, theta_trained)\n",
    "\n",
    "# Function to calculate confusion matrix\n",
    "def confusion_matrix(actual, predicted):\n",
    "    TP = np.sum((actual == 1) & (predicted == 1))\n",
    "    TN = np.sum((actual == 0) & (predicted == 0))\n",
    "    FP = np.sum((actual == 0) & (predicted == 1))\n",
    "    FN = np.sum((actual == 1) & (predicted == 0))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "# Calculate confusion matrix for training and testing sets\n",
    "TP_train, TN_train, FP_train, FN_train = confusion_matrix(y_train, y_train_pred)\n",
    "TP_test, TN_test, FP_test, FN_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Function to calculate sensitivity\n",
    "def sensitivity(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "# Function to calculate specificity\n",
    "def specificity(TN, FP):\n",
    "    return TN / (TN + FP)\n",
    "\n",
    "# Calculate sensitivity and specificity for training and testing sets\n",
    "sensitivity_train = sensitivity(TP_train, FN_train)\n",
    "specificity_train = specificity(TN_train, FP_train)\n",
    "sensitivity_test = sensitivity(TP_test, FN_test)\n",
    "specificity_test = specificity(TN_test, FP_test)\n",
    "\n",
    "# Print confusion matrix, sensitivity, and specificity\n",
    "print(\"Confusion Matrix for Training Set:\")\n",
    "print(\"TP:\", TP_train, \"TN:\", TN_train, \"FP:\", FP_train, \"FN:\", FN_train)\n",
    "print(\"Sensitivity (Training):\", sensitivity_train)\n",
    "print(\"Specificity (Training):\", specificity_train)\n",
    "\n",
    "print(\"\\nConfusion Matrix for Testing Set:\")\n",
    "print(\"TP:\", TP_test, \"TN:\", TN_test, \"FP:\", FP_test, \"FN:\", FN_test)\n",
    "print(\"Sensitivity (Testing):\", sensitivity_test)\n",
    "print(\"Specificity (Testing):\", specificity_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
